{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ddee00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy.signal import convolve2d, convolve\n",
    "from scipy.signal.windows import blackman, gaussian\n",
    "import copy\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import make_swiss_roll,\\\n",
    "                             make_s_curve,\\\n",
    "                             make_moons\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from train_utils import get_capacity, plot_weights_hist, train, get_grad_params\n",
    "from metric_utils import calculate_Q_metrics, \\\n",
    "                         strain, \\\n",
    "                         l2_loss, \\\n",
    "                         to_numpy, \\\n",
    "                         numpy_metric, \\\n",
    "                         cosine_sim\n",
    "\n",
    "from input_utils import DataGenerator, make_random_affine\n",
    "from models_utils import MLP_NonlinearEncoder, \\\n",
    "                         init_weights, \\\n",
    "                         universal_approximator, \\\n",
    "                         dJ_criterion, \\\n",
    "                         gained_function, \\\n",
    "                         adjust_learning_rate, \\\n",
    "                         compute_joint_probabilities, \\\n",
    "                         tsne_loss,\\\n",
    "                         tsne_criterion, \\\n",
    "                         sigmoid, \\\n",
    "                         initialize_nonlinearities\n",
    "\n",
    "from embedding_utils import ConstructUMAPGraph, UMAPLoss, UMAPDataset, umap_criterion_compatibility\n",
    "\n",
    "from pynndescent import NNDescent\n",
    "from umap.umap_ import fuzzy_simplicial_set, make_epochs_per_sample\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import pygad\n",
    "from torchga import TorchGA, model2vector, vector2model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "device = torch.device('cuda:0')\n",
    "N_CPU = mp.cpu_count()\n",
    "SEED = 42\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1a3d5",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9716fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = StandardScaler()\n",
    "\n",
    "input_parameters = {'generator': make_swiss_roll, #make_s_curve, \n",
    "                    'generator_kwargs': {'n_samples':1000, 'noise':1e-2}, # 1e-1\n",
    "                    'unsupervised':True,\n",
    "                    'whiten':True,\n",
    "                    'scaler':SCALER,\n",
    "                    'use_outpt_color':True} \n",
    "\n",
    "create_data = DataGenerator(**input_parameters)\n",
    "\n",
    "inpt, _, color = create_data()\n",
    "\n",
    "N_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efd3c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.42108547e-17, -3.90798505e-17,  1.59872116e-17]),\n",
       " array([1., 1., 1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt.mean(1), inpt.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae0821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.59902408, 1.67350107, 2.00295631]),\n",
       " array([-1.78480188, -1.71298949, -1.66512157]),\n",
       " array([[ 1., -0.,  0.],\n",
       "        [-0.,  1., -0.],\n",
       "        [ 0., -0.,  1.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt.max(1), inpt.min(1), (inpt@inpt.T / inpt.shape[1]).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7744e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_train, inpt_test, color_train, color_test = train_test_split(inpt.T, \n",
    "                                                                  color, \n",
    "                                                                  random_state=42,\n",
    "                                                                  test_size=N_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9dcb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_train_torch = torch.tensor(inpt_train, dtype=torch.float32).to(device)\n",
    "inpt_test_torch = torch.tensor(inpt_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dcd747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([900, 3]), torch.Size([100, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt_train_torch.shape, inpt_test_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ec895",
   "metadata": {},
   "source": [
    "# Setup dataloders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f6ba0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 10 16:36:27 2022 Building RP forest with 7 trees\n",
      "Sun Jul 10 16:36:27 2022 NN descent for 10 iterations\n",
      "\t 1  /  10\n",
      "\t 2  /  10\n",
      "\tStopping threshold met -- exiting after 2 iterations\n",
      "Sun Jul 10 16:36:27 2022 Building RP forest with 5 trees\n",
      "Sun Jul 10 16:36:27 2022 NN descent for 7 iterations\n",
      "\t 1  /  7\n",
      "\t 2  /  7\n",
      "\tStopping threshold met -- exiting after 2 iterations\n"
     ]
    }
   ],
   "source": [
    "graph_constructor = ConstructUMAPGraph(metric='euclidean', \n",
    "                                        n_neighbors=15, \n",
    "                                        random_state=SEED)\n",
    "\n",
    "# (epochs_per_sample, head, tail, weight) \n",
    "train_graph_data = graph_constructor(inpt_train)\n",
    "test_graph_data = graph_constructor(inpt_test)\n",
    "\n",
    "BATCH_SIZE_BP = 2\n",
    "\n",
    "dataset_train = UMAPDataset(inpt_train, \n",
    "                            *train_graph_data, \n",
    "                            device=device, \n",
    "                            batch_size=BATCH_SIZE_BP)\n",
    "\n",
    "dataset_test = UMAPDataset(inpt_test, \n",
    "                           *test_graph_data, \n",
    "                           device=device,\n",
    "                           batch_size=BATCH_SIZE_BP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc18e17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57537, 5565)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d8c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_umap = UMAPLoss(device=device, \n",
    "                         min_dist=0.1,\n",
    "                         negative_sample_rate=5,\n",
    "                         edge_weight=None,\n",
    "                         repulsion_strength=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0814c7",
   "metadata": {},
   "source": [
    "# Adjacent grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd58dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import criterion_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d234285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MLP_adjacent().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d29a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(get_grad_params(network.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a4d65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([Y_to\u001b[38;5;241m.\u001b[39mT, Y_from\u001b[38;5;241m.\u001b[39mT], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m loss_umap \u001b[38;5;241m=\u001b[39m criterion_umap(Y)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss_umap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss_umap\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "maxiter = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for itr,batch in tqdm(enumerate(dataset_train)):\n",
    "    \n",
    "    if itr >= maxiter:\n",
    "        break\n",
    "\n",
    "    assert batch.shape[0] == 2\n",
    "    X_to, X_from = batch\n",
    "    X_to, X_from = X_to.unsqueeze(1), X_from.unsqueeze(1)\n",
    "\n",
    "    \n",
    "    Y_to = network(X_to)\n",
    "    Y_from = network(X_from)\n",
    "\n",
    "    Y = torch.cat([Y_to.T, Y_from.T], dim=0)\n",
    "    loss_umap = criterion_umap(Y)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss_umap.backward(retain_graph=True, create_graph=True)\n",
    "    opt.step()\n",
    "\n",
    "    losses.append(loss_umap.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a616f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48121d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a27281ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLP_adjacent(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "    \n",
    "#         super().__init__()\n",
    "    \n",
    "#         self.W_1 = nn.Parameter(torch.zeros(10, 3), requires_grad=False).to(device)\n",
    "#         self.f_1 = universal_approximator(10, requires_grad=True).to(device)\n",
    "\n",
    "#         self.W_2 = nn.Parameter(torch.zeros(10, 10), requires_grad=False).to(device)\n",
    "#         self.f_2 = universal_approximator(10, requires_grad=True).to(device)\n",
    "\n",
    "#         self.W_3 = nn.Parameter(torch.zeros(2, 10), requires_grad=False).to(device)\n",
    "#         self.f_3 = universal_approximator(2, requires_grad=True).to(device)\n",
    "            \n",
    "#         self.λ = 1e-3    \n",
    "            \n",
    "#         init_weights(self)\n",
    "        \n",
    "#     def update(self):\n",
    "        \n",
    "#         self.W_1 = self.W_1 + self.λ*dW1\n",
    "#         self.W_1 = self.W_1 + self.λ*dW1\n",
    "#         self.W_1 = self.W_1 + self.λ*dW1\n",
    "        \n",
    "\n",
    "#     def forward(self, X):\n",
    "\n",
    "#         Y1 = self.f_1(self.W_1@X)\n",
    "#         dW1 = criterion_rule(X, Y1, self.W_1)\n",
    "#         self.W_1 = self.W_1 + self.λ*dW1\n",
    "#         # updated pass\n",
    "#         Y1 = self.f_1(self.W_1@X)\n",
    "\n",
    "#         Y2 = self.f_2(self.W_2@Y1)\n",
    "#         dW2 = criterion_rule(Y1, Y2, self.W_2)\n",
    "#         self.W_2 = self.W_2 + self.λ*dW2\n",
    "#         # updated pass\n",
    "#         Y2 = self.f_2(self.W_2@Y1)\n",
    "\n",
    "#         Y3 = self.f_3(self.W_3@Y2)\n",
    "#         dW3 = criterion_rule(Y2, Y3, self.W_3)\n",
    "#         self.W_3 = self.W_3 + self.λ*dW3\n",
    "#         # updated pass\n",
    "#         Y3 = self.f_3(self.W_3@Y2)\n",
    "        \n",
    "#         return Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab877acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
